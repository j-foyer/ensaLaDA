{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaged-corner",
   "metadata": {},
   "source": [
    "# Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_random_plus(adata, K):\n",
    "    gene_factor_list = []\n",
    "    n_spots, n_genes = adata.X.shape\n",
    "    X = adata.X\n",
    "    wt = np.zeros((K, n_genes))\n",
    "    dt = np.zeros ((n_spots, K))\n",
    "    all_n_umis = adata.X.sum(axis=1)\n",
    "    for n_UMIs in all_n_umis:\n",
    "        factors = np.random.randint(low = 0,\n",
    "                                    high = K,\n",
    "                                    size = int(n_UMIs))\n",
    "        gene_factor_list.append(factors.tolist())\n",
    "    return gene_factor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_gene_factor_old(gene_factor, K):\n",
    "    gene_factor_count = np.zeros((K, len(gene_factor[1,:])))\n",
    "    for factor in range(K):\n",
    "        count = np.count_nonzero(gene_factor == factor, axis = 0)\n",
    "        gene_factor_count[factor] = count\n",
    "    return gene_factor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = count_gene_factor(gene_factor, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times (across all spots) is each and every gene (columns) assigned to each factor (rows).\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_spot_factor_old(gene_factor, K):\n",
    "    spot_factor_count = np.zeros((len(gene_factor), K))\n",
    "    for factor in range(K):\n",
    "        count = np.count_nonzero(gene_factor == factor, axis = 1)\n",
    "        spot_factor_count[:,factor] = count\n",
    "    return spot_factor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = count_spot_factor(gene_factor, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each spot (rows), how many genes are assigned to each and every factor (columns).\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions n_spots rows and K columns. \n",
    "def count_spot_factor(gene_factor, K):\n",
    "    n_spots, n_genes = adata.X.shape\n",
    "    spot_factor_count = np.zeros((n_spots, K))\n",
    "    for spot in range(n_spots):\n",
    "        spot_list = gene_factor[spot].tolist()\n",
    "        for factor in range(K):\n",
    "            spot_factor_count[spot, factor] = spot_list.count(factor)\n",
    "    return spot_factor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = count_spot_factor(random_factors, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_gene_factor(adata, gene_factor, K): # Ge ids som input\n",
    "    n_spots, n_genes = adata.X.shape\n",
    "    gene_factor_count = np.zeros((K, n_genes))\n",
    "    X = adata.X\n",
    "    for spot in range(n_spots):\n",
    "        spot_list = gene_factor[spot].tolist()\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for gene in range(n_genes):\n",
    "            end += int(X[spot, gene])\n",
    "            for factor in range(K):\n",
    "                gene_factor_count[factor, gene] += spot_list[start: end].count(factor)\n",
    "            start = end\n",
    "    return gene_factor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = count_gene_factor(adata, random_factors, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-sullivan",
   "metadata": {},
   "source": [
    "# Used code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-sauce",
   "metadata": {},
   "source": [
    "## Load data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agricultural-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as an\n",
    "import scipy.stats as st\n",
    "from scipy.spatial import KDTree\n",
    "import math\n",
    "from numba import njit\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assumed-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "behind-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(path):\n",
    "    adata = sc.read_visium(path)\n",
    "    adata.var_names_make_unique()\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aging-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "path =\"/Users/juliafoyer/Documents/Skolarbete/Masters_thesis/human_breast_cancer_ST_data\"\n",
    "adata = LoadData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "planned-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(adata.X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X[4] = adata.X[4] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nonprofit-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "approved-chambers",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_visium(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "absolute-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(adata : an.AnnData, select_hvg : bool = True)-> an.AnnData:\n",
    "    adata.var_names_make_unique()\n",
    "    X = np.array(adata.X.todense())\n",
    "    adata.X = X\n",
    "    if select_hvg:\n",
    "        sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes = 1000)\n",
    "#        adata = adata[:,adata.var.highly_variable_genes.values]\n",
    "        adata = adata[:,adata.var.highly_variable.values]\n",
    "        adata.X = (np.exp(adata.X) -1).round(0)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-picture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "median-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[:,adata.var.highly_variable.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worse-hopkins",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type SparseCSRView which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/isbad2/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: exp not found",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-728718d07741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Another option is to save genes, reload data and then filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type SparseCSRView which has no callable exp method"
     ]
    }
   ],
   "source": [
    "# Another option is to save genes, reload data and then filter\n",
    "adata.X = (np.exp(adata.X) -1).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "spots = adata.obs_names\n",
    "genes = adata.var_names\n",
    "n_spots = len(adata.obs_names)\n",
    "n_genes = len(adata.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_influence = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_fun2(p,q):\n",
    "    #Bhattacharyya distance\n",
    "    return - np.log(np.sqrt(p*q).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distance_fun2(theta[0], theta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distance_fun(theta[0], theta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "numerous-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x speed\n",
    "@njit(parallel=False)\n",
    "def distance_fun(p,q):\n",
    "    #Bhattacharyya distance\n",
    "    return - np.log(np.sqrt(p*q).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "concerned-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# njit makes it worse\n",
    "#@njit(parallel=False)\n",
    "def log_potential(edge_influence, current_theta, neighbour_theta):\n",
    "    return edge_influence * distance_fun(current_theta, neighbour_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "concrete-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nbrhd(adata,\n",
    "            n_neighbours):\n",
    "    \"\"\" add short description here\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    kd = KDTree(adata.obsm[\"spatial\"])\n",
    "    dist,indx = kd.query(adata.obsm[\"spatial\"], k = n_neighbours) # why not +1?\n",
    "    no_nbr = np.isinf(dist)\n",
    "    dist[no_nbr] = 0\n",
    "    dist[~no_nbr] = 1\n",
    "    indx[no_nbr] = -1\n",
    "    return dist, indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "broadband-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, indx = build_nbrhd(adata, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_theta(0, theta, dt, indx, dist, edge_influence, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demographic-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nz(dt):\n",
    "    nz = dt.sum(axis=0)\n",
    "    return nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz = get_nz(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def draw_new_factor(umi_factors,\n",
    "                    dt,\n",
    "                    wt,\n",
    "                    nz,\n",
    "                    d,\n",
    "                    index,\n",
    "                    w):\n",
    "    z = umi_factors[d][index]\n",
    "    dt[d, z] = dt[d, z] - 1\n",
    "    wt[z, w] = wt[z, w] - 1\n",
    "    nz[z] = nz[z] - 1\n",
    "    pz = np.divide(np.multiply(dt[d, :], wt[:, w]), nz)\n",
    "    z = np.random.multinomial(1, (pz / pz.sum())).argmax()\n",
    "    umi_factors[d][index] = z \n",
    "    dt[d, z] = dt[d, z] + 1\n",
    "    wt[z, w] = wt[z, w] + 1\n",
    "    nz[z] = nz[z] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def draw_new_factor(sub_list,\n",
    "                    dt,\n",
    "                    wt,\n",
    "                    nz,\n",
    "                    d,\n",
    "                    index,\n",
    "                    w):\n",
    "    \n",
    "    z = sub_list[index]\n",
    "    dt[d, z] = dt[d, z] - 1\n",
    "    wt[z, w] = wt[z, w] - 1\n",
    "    nz[z] = nz[z] - 1\n",
    "    pz = np.divide(np.multiply(dt[d, :], wt[:, w]), nz)\n",
    "    z = np.random.multinomial(1, (pz / pz.sum())).argmax()\n",
    "    sub_list[index] = z \n",
    "    dt[d, z] = dt[d, z] + 1\n",
    "    wt[z, w] = wt[z, w] + 1\n",
    "    nz[z] = nz[z] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def draw_new_factor(sub_list,\n",
    "                    dt,\n",
    "                    wt,\n",
    "                    nz,\n",
    "                    d,\n",
    "                    index,\n",
    "                    w):\n",
    "    \n",
    "    z = sub_list[index]\n",
    "    dt[d, z] -=  1\n",
    "    wt[z, w] -= 1\n",
    "    nz[z] -= 1\n",
    "    pz = np.divide(np.multiply(dt[d, :], wt[:, w]), nz)\n",
    "    z = np.random.multinomial(1, (pz / pz.sum())).argmax()\n",
    "    sub_list[index] = z \n",
    "    dt[d, z] += 1\n",
    "    wt[z, w] += 1\n",
    "    nz[z] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "draw_new_factor(umi_factors[0], dt, wt, nz, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "draw_new_factor(umi_factors, dt, wt, nz, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(umi_factors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_theta(0, theta, dt, indx, dist, edge_influence, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.random.dirichlet(dt[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def log_pdf_dirichlet(x,alpha):\n",
    "    l_beta_top = 0\n",
    "    l_beta_bot = 0\n",
    "    frac = 0\n",
    "    for _a,_x in zip(alpha,x):\n",
    "        l_beta_top += m.log(m.gamma(_a))\n",
    "        l_beta_bot += _a\n",
    "        frac += (_a - 1)*m.log(_x)\n",
    "    l_beta_bot = np.log(m.gamma(l_beta_bot))\n",
    "    return frac + l_beta_bot - l_beta_top\n",
    "\n",
    "@njit(parallel=False)\n",
    "def dirichlet_sample(alpha):\n",
    "    n = len(alpha)\n",
    "    y = np.zeros(n)\n",
    "    ys = 0\n",
    "    for i in range(n):\n",
    "        y[i] = np.random.gamma(shape=alpha[i],scale=1)\n",
    "        ys += y[i]\n",
    "    y = y / ys\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "spot = 0\n",
    "alpha = dt[spot,:]\n",
    "#alpha = np.array([[253., 238., 234.]])\n",
    "print(alpha)\n",
    "print(type(alpha))\n",
    "theta_mat = np.zeros((1, 3))\n",
    "theta_mat[0,:] = theta[spot,:]\n",
    "#x = np.array([[0.34820951, 0.33147761, 0.32031288]])\n",
    "print(theta_mat[0,:])\n",
    "print(type(theta_mat[0,:]))\n",
    "old_log_proposal = log_pdf_dirichlet(x, alpha)\n",
    "print(old_log_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_theta = dirichlet_sample(alpha)\n",
    "print(new_theta)\n",
    "new_log_proposal = log_pdf_dirichlet(new_theta, alpha)\n",
    "print(new_log_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_theta(spot, theta, dt, indx, dist, edge_influence, K, n_iter = 10):\n",
    "        \n",
    "#    proposal_dist = st.dirichlet(dt[spot,:])\n",
    "    alpha = dt[spot,:]\n",
    "    \n",
    "    theta_mat = np.zeros((n_iter+1, K))\n",
    "        \n",
    "    theta_mat[0,:] = theta[spot,:]\n",
    "#    old_log_proposal = proposal_dist.logpdf(theta_mat[0,:])\n",
    "    old_log_proposal = log_pdf_dirichlet(theta_mat[0,:], alpha)\n",
    "    old_log_target = log_potential(edge_influence, theta_mat[0,:], theta[indx[spot,:]])\n",
    "    old_log_target *= dist[spot,:] # Keep only those that are real neighbours. * 0 cancels false neighbours.\n",
    "    old_log_target = old_log_target.sum()\n",
    "    \n",
    "    for it in range(1,n_iter+1):\n",
    "#        new_theta = proposal_dist.rvs()[0]\n",
    "        new_theta = dirichlet_sample(alpha)\n",
    "#        new_log_proposal = proposal_dist.logpdf(new_theta)\n",
    "        new_log_proposal = log_pdf_dirichlet(new_theta, alpha)\n",
    "        new_log_target = log_potential(edge_influence, new_theta, theta[indx[spot,:]])\n",
    "        new_log_target *= dist[spot,:]\n",
    "        new_log_target = new_log_target.sum()\n",
    "                    \n",
    "        log_u = new_log_target + old_log_proposal - old_log_target - new_log_proposal\n",
    "        u = np.exp(log_u) \n",
    "        a = min(u,1)\n",
    "        \n",
    "        if np.random.random() < a:\n",
    "            theta_mat[it,:] = new_theta\n",
    "            old_log_target = new_log_target\n",
    "            old_log_proposal = new_log_proposal\n",
    "        else:\n",
    "            theta_mat[it,:] = theta_mat[it-1,:]\n",
    "                    \n",
    "        theta[spot,:] = theta_mat.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def sample_theta(spot, theta, dt, indx, dist, edge_influence, K, n_iter = 10):\n",
    "        \n",
    "    n_topics = dt.shape[0]\n",
    "    theta_mat = np.zeros((n_iter+1, K))\n",
    "    \n",
    "    proposal_dist = np.zeros(n_topics)\n",
    "    proposal_dist = np.random.dirichlet(dt[spot,:])\n",
    "\n",
    "        \n",
    "    theta_mat[0,:] = theta[spot,:]\n",
    "    old_log_proposal = proposal_dist.logpdf(theta_mat[0,:])\n",
    "    old_log_target = log_potential(edge_influence, theta_mat[0,:], theta[indx[spot,:]])\n",
    "    old_log_target *= dist[spot,:] # Keep only those that are real neighbours. * 0 cancels false neighbours.\n",
    "    old_log_target = old_log_target.sum()\n",
    "    \n",
    "    for it in range(1,n_iter+1):\n",
    "        new_theta = proposal_dist.rvs()[0] # what is the 0?\n",
    "        new_log_proposal = proposal_dist.logpdf(new_theta)\n",
    "        new_log_target = log_potential(edge_influence, new_theta, theta[indx[spot,:]])\n",
    "        new_log_target = new_log_target * dist[spot,:]\n",
    "        new_log_target = new_log_target.sum()\n",
    "                    \n",
    "        log_u = new_log_target + old_log_proposal - old_log_target - new_log_proposal\n",
    "        u = np.exp(log_u) \n",
    "        a = min(u,1)\n",
    "        \n",
    "        if np.random.random() < a:\n",
    "            theta_mat[it,:] = new_theta\n",
    "            old_log_target = new_log_target\n",
    "            old_log_proposal = new_log_proposal\n",
    "        else:\n",
    "            theta_mat[it,:] = theta_mat[it-1,:]\n",
    "                    \n",
    "        theta[spot,:] = theta_mat.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "inappropriate-keeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.5 * 400 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-allah",
   "metadata": {},
   "source": [
    "## Assign random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "organic-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_random(adata, K):\n",
    "    umi_factor_list = []\n",
    "    all_n_umis = adata.X.sum(axis=1)\n",
    "    for n_UMIs in all_n_umis:\n",
    "        factors = np.random.randint(low = 0,\n",
    "                                    high = K,\n",
    "                                    size = int(n_UMIs))\n",
    "        umi_factor_list.append(factors)\n",
    "    umi_factor_list = np.array(umi_factor_list, dtype=object)\n",
    "    return umi_factor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brown-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "umi_factors = assign_random(adata, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_edge_influence(lambda0, theta, indx_sel, K):\n",
    "    DB = lambda p, q, X: - math.log(Bhatt_coeff(p, q, X))\n",
    "    edge_influence = []\n",
    "    n_spots = len(indx_sel)\n",
    "    X = K\n",
    "    for spot in range(n_spots):\n",
    "        p = theta[0]\n",
    "        influences = []\n",
    "        neighbours = indx_sel[spot][1:]\n",
    "        for neighbour in neighbours:\n",
    "            q = theta[neighbour]\n",
    "            influences.append(np.random.exponential(lambda0 + DB(p, q, X)))\n",
    "        edge_influence.append(influences)\n",
    "    return np.array(edge_influence, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_influence = first_edge_influence(lambda0, theta, indx_sel, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-honolulu",
   "metadata": {},
   "source": [
    "## Get IDs and count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "labeled-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_dt_wt(adata, umi_factors, K):\n",
    "    n_spots, n_genes = adata.X.shape\n",
    "    X = adata.X\n",
    "    ids = []\n",
    "    dt = np.zeros((n_spots, K))\n",
    "    wt = np.zeros((K, n_genes))\n",
    "    for spot in range(n_spots):\n",
    "        ids_spot = []\n",
    "        spot_list = umi_factors[spot].tolist()\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for gene in range(n_genes):\n",
    "            n_umis = int(X[spot, gene])\n",
    "            ids_spot += [gene] * n_umis\n",
    "            end += n_umis\n",
    "            for factor in range(K):\n",
    "                wt[factor, gene] += spot_list[start: end].count(factor)\n",
    "            start = end\n",
    "        ids.append(ids_spot)\n",
    "        for factor in range(K):\n",
    "            dt[spot, factor] = spot_list.count(factor)\n",
    "    return ids, dt, wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "specific-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_dt_wt(adata,\n",
    "                  umi_factors,\n",
    "                  K,\n",
    "                  alpha = 0.1,\n",
    "                  beta = 0.1):\n",
    "    \"\"\" add short description here\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    adata : an.AnnData\n",
    "        anndata object to study\n",
    "    umi_factors. List[np.ndarray]\n",
    "        List of arrays. Element j in list i represents\n",
    "        topic that word j belongs to in spot i\n",
    "    K: int\n",
    "        number of topics\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_spots, n_genes = adata.X.shape\n",
    "    X = adata.X\n",
    "    ids = []\n",
    "    dt = np.zeros((n_spots, K)) + alpha\n",
    "    wt = np.zeros((K, n_genes)) + beta\n",
    "    \n",
    "    for spot in range(n_spots):\n",
    "        ids_spot = []\n",
    "        spot_list = umi_factors[spot].tolist()\n",
    "        start = 0\n",
    "        end = 0\n",
    "        for gene in range(n_genes):\n",
    "            n_umis = int(X[spot, gene])\n",
    "            ids_spot += [gene] * n_umis\n",
    "            end += n_umis\n",
    "            for factor in range(K):\n",
    "                wt[factor, gene] += spot_list[start: end].count(factor)\n",
    "            start = end\n",
    "        ids.append(ids_spot)\n",
    "        for factor in range(K):\n",
    "            dt[spot, factor] += spot_list.count(factor)\n",
    "    return ids, dt, wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "worse-printer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0, 1, 2, ..., 0, 0, 2]), array([1, 2, 1, ..., 2, 2, 2]),\n",
       "       array([2, 0, 1, ..., 0, 1, 1]), ...,\n",
       "       array([0, 1, 2, ..., 0, 1, 1]), array([0, 1, 0, ..., 0, 0, 0]),\n",
       "       array([2, 0, 2, ..., 0, 1, 1])], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umi_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "olympic-litigation",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c124afb85902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ids_dt_wt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mumi_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-68fc2b85c5b1>\u001b[0m in \u001b[0;36mget_ids_dt_wt\u001b[0;34m(adata, umi_factors, K, alpha, beta)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mn_umis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mids_spot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_umis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn_umis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isbad2/lib/python3.7/site-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/isbad2/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_get_intXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    646\u001b[0m         indptr, indices, data = get_csr_submatrix(\n\u001b[1;32m    647\u001b[0m             \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             major, major + 1, minor, minor + 1)\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ids, dt, wt = get_ids_dt_wt(adata, umi_factors, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.all(np.sum(dt,axis=1) == np.sum(X,axis=1))), \"total UMI's in spot and dt rowsums must be equal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-design",
   "metadata": {},
   "source": [
    "## Functions for calculating theta and phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(dt):\n",
    "    n_spots, K = dt.shape\n",
    "    theta = np.zeros((n_spots, K))\n",
    "    for spot in range(n_spots):\n",
    "        for factor in range(K):\n",
    "            theta[spot, factor] = dt[spot, factor]/np.sum(dt, axis=1)[spot]\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = get_theta(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phi(wt): # I don't use this...\n",
    "    K = 3\n",
    "    phi = np.zeros((K, n_genes))\n",
    "    for factor in range(K):\n",
    "        for gene in range(n_genes):\n",
    "            phi[factor, gene] = gene_factor_count[factor, gene]/np.sum(gene_factor_count, axis=1)[factor]\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phi(wt):\n",
    "    phi = gene_factor_count/gene_factor_count.sum(axis=1, keepdims=True)\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = get_phi(wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-paradise",
   "metadata": {},
   "source": [
    "## Get neighbours and graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKNN(adata, n_neighbours):\n",
    "    kd = KDTree(adata.obsm[\"spatial\"])\n",
    "    dist,indx = kd.query(adata.obsm[\"spatial\"], k = n_neighbours + 1)\n",
    "    return dist, indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, indx = findKNN(adata, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,c = np.unique(indx[:,-1],return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_false_neighbours(dist, indx, eps = 300):\n",
    "    dist_sel = []\n",
    "    indx_sel = []\n",
    "    for i in range(len(dist)):\n",
    "        dist_sel.append([])\n",
    "        indx_sel.append([])\n",
    "        for j in range(len(dist[i])):\n",
    "            if dist[i][j] < eps:\n",
    "                dist_sel[i].append(dist[i][j])\n",
    "                indx_sel[i].append(indx[i][j])\n",
    "        dist_sel[i] = np.array(dist_sel[i])\n",
    "        indx_sel[i] = np.array(indx_sel[i])\n",
    "    return np.array(dist_sel, dtype=object), np.array(indx_sel, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sel, indx_sel = remove_false_neighbours(dist, indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indx_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = 0\n",
    "for i in indx:\n",
    "    edges += len(i)\n",
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_E(indx_sel):\n",
    "    edges = 0\n",
    "    for i in indx_sel:\n",
    "        edges += len(i) - 1\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = get_E(indx_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-parallel",
   "metadata": {},
   "source": [
    "## Functions for Gibbs sampling of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_lambda(E, edge_influence, lambda_a = 0.01, lambda_b = 0.01):\n",
    "    sum_edge_influences = 0\n",
    "    for edge in edge_influence:\n",
    "        sum_edge_influences += sum(edge)\n",
    "    shape = lambda_a + E\n",
    "    rate = 1 / (lambda_b + sum_edge_influences)\n",
    "    lambda_parameter = np.random.gamma(shape, rate, 1)\n",
    "    return lambda_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_inv_edge_influence(edge_influence, lambda_parameter, theta, indx_sel, K):\n",
    "    n_spots = len(indx_sel)\n",
    "    X = K\n",
    "    for spot in range(n_spots):\n",
    "        p = theta[spot]\n",
    "        index = 1\n",
    "        n_neighbours = len(indx_sel[spot][1:])\n",
    "        for index in range(n_neighbours):\n",
    "            neighbour = indx_sel[spot][index+1]\n",
    "            q = theta[neighbour]\n",
    "            edge_influence[spot][index] = np.random.exponential(lambda_parameter - math.log(Bhatt_coeff(p, q, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_new_factor(gene_factor, ids, spot, w, dt, wt, theta, K, beta = 0.1):\n",
    "    factor0 = gene_factor[spot][w]\n",
    "    gene_id = ids[spot][w]\n",
    "    dt[spot, factor0] -= 1\n",
    "    wt[factor0, gene_id] -= 1\n",
    "    left = theta[spot,]\n",
    "    right = (wt[:,gene_id] + beta) / (wt.sum(axis=0)[gene_id] + K * beta)\n",
    "    pvals = left*right\n",
    "    pvals = pvals / pvals.sum()\n",
    "    factor1 = np.random.choice(K, p = pvals)\n",
    "    dt[spot, factor1] +=  1\n",
    "    wt[factor1, gene_id] += 1\n",
    "    gene_factor[spot][w] = factor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gibbs(gene_factor, ids, dt, wt, theta, K, iterations, edge_influence, lambda_parameter, indx_sel, E, adata, beta = 0.1):\n",
    "    for it in range(iterations):\n",
    "        for spot in range(len(gene_factor)):\n",
    "            for w in range(len(gene_factor[spot])):\n",
    "                draw_new_factor(gene_factor, ids, spot, w, dt, wt, theta, K)\n",
    "        sample_edge_influence(edge_influence, lambda_parameter, theta, indx_sel, K)\n",
    "        lambda_parameter = sample_lambda(E, edge_influence, lambda_a = 0.01, lambda_b = 0.01)\n",
    "        metr_hast(adata, theta, indx_sel, edge_influence, lambda_parameter, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Before metropolis-Hastings was included.\n",
    "Gibbs(random_factors, ids, dt, wt, theta, 3, 1, edge_influence, lambda_parameter, indx_sel, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# After metropolis-Hastings included. No difference. Draw_new_factor takes all the time.\n",
    "Gibbs(random_factors, ids, dt, wt, theta, 3, 1, edge_influence, lambda_parameter, indx_sel, E, adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-rabbit",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings sampling of theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=False)\n",
    "def Bhatt_coeff(p, q, X):\n",
    "    BC = 0\n",
    "    for x in range(X):\n",
    "        BC += math.sqrt(p[x]*q[x])\n",
    "    return BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metr_hast(adata, theta, indx_sel, edge_influence, lambda_parameter, K, iterations = 10):\n",
    "    \n",
    "    # Prepare proposal distribution    \n",
    "    dist_g = lambda x: np.random.dirichlet(x)\n",
    "    \n",
    "    # Acceptance probability\n",
    "    DB = lambda p, q, X: - math.log(Bhatt_coeff(p, q, X))\n",
    "    X = K\n",
    "    \n",
    "    # Metropolis-Hastings sampling\n",
    "    n_spots, n_genes = adata.X.shape    \n",
    "    for spot in range(n_spots):\n",
    "        log_a_prob0 = 0 # Cannot use from last Gibbs iteration, because there will be new edge_infl and lambdas.\n",
    "        log_a_prob1 = 0\n",
    "        p0 = theta[spot]\n",
    "        p1 = dist_g(np.sum(theta, axis=0)) \n",
    "        neighbours = indx_sel[spot][1:]\n",
    "        index = 0\n",
    "        for neighbour in neighbours:\n",
    "            q = theta[neighbour]\n",
    "            log_edge_potential0 = - DB(p0,q,X) * edge_influence[spot][index] # = - DB(p,q,X) / inv_ldd ? Eller?\n",
    "            log_edge_potential1 = - DB(p1,q,X) * edge_influence[spot][index]\n",
    "            log_a_prob0 += log_edge_potential0\n",
    "            log_a_prob1 += log_edge_potential1\n",
    "            index += 1\n",
    "        a_prob = min(1, np.exp(log_a_prob1 - log_a_prob0)) \n",
    "        print(a_prob) # This is really large. Maybe that's normal because everything is better than random?\n",
    "        if np.random.random() < a_prob:\n",
    "            p0 = p1\n",
    "        print(theta[spot])\n",
    "        theta[spot] = p0\n",
    "        print(theta[spot])\n",
    "        \n",
    "        \n",
    "##        neighbours = indx[spot][1:]\n",
    "  #      for neighbour in neighbours:\n",
    " #           q = theta[neighbour]\n",
    " #           inv_ldd = 1 / edge_influence[neighbour]\n",
    " #           log_edge_potential = - DB(p,q,X) / inv_ldd\n",
    " #           log_a_prob +=log_edge_potential\n",
    " #       a_prob = min(1, np.exp(log_a_prob))\n",
    " #           \n",
    " #       theta1 = dist_g(theta0)\n",
    "            \n",
    "            \n",
    "  #          a = edge_potentials1 / edge_potentials0\n",
    "  #          a = min(1, a)\n",
    "  #          if np.random.random() < a:\n",
    "  #              theta0 = theta1\n",
    "  #      theta[spot] = theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_prob, lambda_parameter = acc_prob(0, indx, theta, 3, lambda_parameter0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.dirichlet((1279, 1296, 1223))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.dirichlet((0.3, 0.3, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "metr_hast(adata, theta, indx_sel, edge_influence, lambda_parameter, 3, iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_prob(spot, indx, theta, K, inv_ldd,lambda_parameter):\n",
    "    DB = lambda p, q, X: - math.log(Bhatt_coeff(p, q, X))\n",
    "#    get_lambda_parameter = lambda shape, scale : np.random.gamma(shape, scale, 1)\n",
    "    get_edge_influence = lambda p, q, X : 1 / (np.random.exponential(lambda_parameter + DB(p, q, X))) # \"measure of strength\"\n",
    "#    get_edge_potential = lambda p, q, X : math.exp(- get_edge_influence(p, q, X) * DB(p, q, X))\n",
    "\n",
    "    p = theta[spot]\n",
    "    \n",
    "    a_prob = 1\n",
    "    neighbours = indx[spot][1:]\n",
    "    for neighbour in neighbours:\n",
    "        q = theta[neighbour]\n",
    "        X = K\n",
    "       # edge_potential = math.exp(- 1 / (np.random.exponential(lambda_parameter + DB(p, q, X))) * DB(p, q, X))\n",
    "        #edge_potential = math.exp(-DB(p, q, X) / inv_ldd[neighbour])\n",
    "        #print(edge_potential)\n",
    "        log_edge_potential = - DB(p,q,X) / inv_ldd[neighbour]\n",
    "        #a_prob *= edge_potential\n",
    "        log_a_prob +=log_edge_potential\n",
    "    a_prob = min(1, np.exp(a_prob))\n",
    "    \n",
    "    # Get lambda parameter for next round\n",
    "    lambda_a = 0.01\n",
    "    lambda_b = 0.01\n",
    "    E = np.sum(indx) / 2\n",
    "    shape = lambda_a + E\n",
    "    scale = lambda_b + get_edge_influence(p, q, X) * E\n",
    "    lambda_parameter = np.random.gamma(shape, 1/scale, 1)\n",
    "    \n",
    "    return a_prob, lambda_parameter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
